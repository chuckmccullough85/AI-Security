{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evasion Attacks\n",
    "\n",
    "In this lab, we will use the MNIST dataset to train an SVM model to classify handwritten digits.\n",
    "\n",
    "First, get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secml\n",
    "\n",
    "from secml.data.loader import CDataLoaderMNIST\n",
    "\n",
    "# MNIST dataset will be downloaded and cached if needed\n",
    "loader = CDataLoaderMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Now, let's train the model only for digits 5 and 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 999\n",
    "\n",
    "n_tr = 100  # Number of training set samples\n",
    "n_val = 500  # Number of validation set samples\n",
    "n_ts = 500  # Number of test set samples\n",
    "\n",
    "digits = (5, 9)\n",
    "\n",
    "tr_val = loader.load('training', digits=digits, num_samples=n_tr + n_val)\n",
    "ts = loader.load('testing', digits=digits, num_samples=n_ts)\n",
    "\n",
    "# Split in training and validation set\n",
    "tr = tr_val[:n_tr, :]\n",
    "val = tr_val[n_tr:, :]\n",
    "\n",
    "# Normalize the features in `[0, 1]`\n",
    "tr.X /= 255\n",
    "val.X /= 255\n",
    "ts.X /= 255\n",
    "\n",
    "from secml.ml.classifiers import CClassifierSVM\n",
    "# train SVM in the dual space, on a linear kernel, as needed for poisoning\n",
    "clf = CClassifierSVM(C=10, kernel='linear')\n",
    "\n",
    "print(\"Training of classifier...\")\n",
    "clf.fit(tr.X, tr.Y)\n",
    "\n",
    "# Compute predictions on a test set\n",
    "y_pred = clf.predict(ts.X)\n",
    "\n",
    "# Metric to use for performance evaluation\n",
    "from secml.ml.peval.metrics import CMetricAccuracy\n",
    "metric = CMetricAccuracy()\n",
    "\n",
    "# Evaluate the accuracy of the classifier\n",
    "acc = metric.performance_score(y_true=ts.Y, y_pred=y_pred)\n",
    "\n",
    "print(\"Accuracy on test set: {:.2%}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The evasion attack\n",
    "For the attack, we will modify pixels in the test data (perturbation) to make the model misclassify the images. We will generate an l2 pertubation with a max eps radius of 2.5 from the initial points.\n",
    "\n",
    "We are using the PGD attack to generate the adversarial examples. The PGD attack is a multi-step variant of the FGSM attack. It generates adversarial examples by applying a small perturbation to each input feature. The perturbation is computed by taking a small step in the direction that maximizes the loss function. The PGD attack is more powerful than the FGSM attack because it performs multiple steps of optimization, which allows it to find more effective perturbations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For simplicity, let's attack a subset of the test set\n",
    "attack_ds = ts[:25, :]\n",
    "\n",
    "noise_type = 'l2'  # Type of perturbation 'l1' or 'l2'\n",
    "dmax = 2.5  # Maximum perturbation\n",
    "lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
    "y_target = None  # None if `error-generic` or a class label for `error-specific`\n",
    "\n",
    "# Should be chosen depending on the optimization problem\n",
    "solver_params = {\n",
    "    'eta': 0.5, \n",
    "    'eta_min': 2.0, \n",
    "    'eta_max': None,\n",
    "    'max_iter': 100, \n",
    "    'eps': 1e-6\n",
    "}\n",
    "\n",
    "from secml.adv.attacks import CAttackEvasionPGDLS\n",
    "pgd_ls_attack = CAttackEvasionPGDLS(classifier=clf,\n",
    "                                    double_init_ds=tr,\n",
    "                                    distance=noise_type, \n",
    "                                    dmax=dmax,\n",
    "                                    solver_params=solver_params,\n",
    "                                    y_target=y_target)\n",
    "\n",
    "print(\"Attack started...\")\n",
    "eva_y_pred, _, eva_adv_ds, _ = pgd_ls_attack.run(attack_ds.X, attack_ds.Y)\n",
    "print(\"Attack complete!\")\n",
    "\n",
    "acc = metric.performance_score(\n",
    "    y_true=attack_ds.Y, y_pred=clf.predict(attack_ds.X))\n",
    "acc_attack = metric.performance_score(\n",
    "    y_true=attack_ds.Y, y_pred=eva_y_pred)\n",
    "\n",
    "print(\"Accuracy on reduced test set before attack: {:.2%}\".format(acc))\n",
    "print(\"Accuracy on reduced test set after attack: {:.2%}\".format(acc_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe how the classifier trained on the MNIST dataset has been \n",
    " *successfully evaded* by the adversarial examples generated by our attack.\n",
    " \n",
    " ---\n",
    " \n",
    "Let's now visualize few of the adversarial examples. The first row are the \n",
    " original samples and the second row are the adversarial examples. Above each\n",
    " digit it is shown the true label and the predicted label in parenthesis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secml.figure import CFigure\n",
    "# Only required for visualization in notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Let's define a convenience function to easily plot the MNIST dataset\n",
    "def show_digits(samples, preds, labels, digs, n_display=8):\n",
    "    samples = samples.atleast_2d()\n",
    "    n_display = min(n_display, samples.shape[0])\n",
    "    fig = CFigure(width=n_display*2, height=3)\n",
    "    for idx in range(n_display):\n",
    "        fig.subplot(2, n_display, idx+1)\n",
    "        fig.sp.xticks([])\n",
    "        fig.sp.yticks([])\n",
    "        fig.sp.imshow(samples[idx, :].reshape((28, 28)), cmap='gray')\n",
    "        fig.sp.title(\"{} ({})\".format(digits[labels[idx].item()], digs[preds[idx].item()]),\n",
    "                     color=(\"green\" if labels[idx].item()==preds[idx].item() else \"red\"))\n",
    "    fig.show()\n",
    "\n",
    "show_digits(attack_ds.X, clf.predict(attack_ds.X), attack_ds.Y, digits)\n",
    "show_digits(eva_adv_ds.X, clf.predict(eva_adv_ds.X), eva_adv_ds.Y, digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Finally, let's show the model accuracy on different perturbation levels. Note - this will take a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perturbation levels to test\n",
    "from secml.array import CArray\n",
    "e_vals = CArray.arange(start=0, step=0.1, stop=4.5)\n",
    "\n",
    "from secml.adv.seceval import CSecEval\n",
    "sec_eval = CSecEval(\n",
    "    attack=pgd_ls_attack, param_name='dmax', param_values=e_vals)\n",
    "\n",
    "# Run the security evaluation using the test set\n",
    "print(\"Running security evaluation on subset...\")\n",
    "sec_eval.run_sec_eval(ts[:25, :])\n",
    "\n",
    "from secml.figure import CFigure\n",
    "fig = CFigure(height=5, width=15)\n",
    "\n",
    "# Convenience function for plotting the Security Evaluation Curve\n",
    "fig.sp.plot_sec_eval(\n",
    "    sec_eval.sec_eval_data, marker='o', label='SVM RBF', show_average=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the chart, accuracy is not affected until the perturbation circle radius is greater than .05.  Then we see accuracy begin to drop off.  This is a good example of how adversarial attacks can be used to fool machine learning models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
